{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JAX Day 1 Evening - Parallelism Basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPJWwh43TTSCIQR+ViyLW4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/halcy/LearningJAX/blob/main/JAX_Day_1_Evening_Parallelism_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZsydUDmQuBT"
      },
      "source": [
        "# JAX Day 1 - Evening - Parallelism\n",
        "\n",
        "Now that we can train an MNIST digits classifier, lets take a step back and see how to do some basic parallelism so we can go faster!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI8gUnVLwrlV",
        "outputId": "0bfbeb39-d1fc-468d-8580-0c4c59c1ccf1"
      },
      "source": [
        "# Catchall \"what is this runtime\" cell\n",
        "!nvidia-smi\n",
        "GPU = !nvidia_smi\n",
        "\n",
        "if len(GPU) > 3:\n",
        "    GPU = True\n",
        "else:\n",
        "    GPU = False\n",
        "\n",
        "!vmstat\n",
        "print(\"\")\n",
        "\n",
        "import os\n",
        "\n",
        "if \"COLAB_TPU_ADDR\" in os.environ:\n",
        "    from tensorflow.python.profiler import profiler_client\n",
        "    print(\"tpu:\", os.environ['COLAB_TPU_ADDR'])\n",
        "    tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n",
        "    print(profiler_client.monitor(tpu_profile_service_address, 100, 2).strip())\n",
        "    TPU = True\n",
        "else:\n",
        "    print(\"tpu: no\")\n",
        "    TPU = False\n",
        "\n",
        "CPUS = os.cpu_count()\n",
        "print(\"\\ncpus:\", CPUS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n",
            " r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n",
            " 7  0      0 10594840 102420 2037596    0    0   863    21  178  328  2  1 96  1  0\n",
            "\n",
            "tpu: 10.103.29.18:8470\n",
            "Timestamp: 17:06:33\n",
            "  TPU type: TPU v2\n",
            "  Utilization of TPU Matrix Units (higher is better): 0.000%\n",
            "\n",
            "cpus: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcWWDPaGQmTG"
      },
      "source": [
        "# Basic setup and data loading\n",
        "\n",
        "Basically the same as the previous notebook, but now we also want xmap and mesh from jax.experimental.maps, to parallelize computations across multiple TPU devices, and we don't actually need MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmhGBH-7zUJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb24cc92-c381-4cd0-be97-7fafcb2b595d"
      },
      "source": [
        "# Set JAX, haiku and optax up for the TPU\n",
        "!pip install --upgrade -q jax jaxlib dm-haiku optax tqdm\n",
        "\n",
        "import requests\n",
        "import os\n",
        "\n",
        "if 'TPU_DRIVER_MODE' not in globals():\n",
        "    url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver_nightly'\n",
        "    resp = requests.post(url)\n",
        "    TPU_DRIVER_MODE = 1\n",
        "\n",
        "# TPU driver as backend for JAX\n",
        "from jax.config import config\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 708 kB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 284 kB 60.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 63.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.6 MB/s \n",
            "\u001b[?25h  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHfiPH6dvtTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e765f7e-9847-4218-9470-dd20ef4e7b1d"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import jit, nn\n",
        "\n",
        "from jax.experimental.maps import xmap, mesh\n",
        "\n",
        "import haiku as hk\n",
        "import optax\n",
        "\n",
        "import tqdm\n",
        "\n",
        "# Pinky promise: We are now aware xmap is experimental, and will adjust our expectations accordingly\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"xmap is an experimental feature and probably has bugs!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3cc9d4ba3120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaps\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhaiku\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'haiku'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbHUX9RfxFKs"
      },
      "source": [
        "# Generate PRNG state\n",
        "prng = jax.random.PRNGKey(23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgVg9FFcVCdV"
      },
      "source": [
        "# Basic data parallelism example\n",
        "xmap lets us run a function in parallel on all available devices with relative ease. It does this using named axes. Lets see how, and how we can use that to Go Fast!\n",
        "\n",
        "Note that we're only using named axes in a very simple manner here - it wouldn't have been hard to just use positional axes instead. However, named axes allow jax to keep track of how to split computation across more than just batches, which seems fairly powerful and might be useful later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "xfbFpsw7VGsv",
        "outputId": "60ee887b-66c5-4376-c6c0-7eaba63b7ebf"
      },
      "source": [
        "# A very simple feedforward network\n",
        "def simple_nn(x):\n",
        "    for i in range(100):\n",
        "        lin1 = hk.Linear(100)\n",
        "        x = lin1(x)\n",
        "    lin2 = hk.Linear(1)        \n",
        "    x = lin2(x)\n",
        "    return x\n",
        "\n",
        "# Set up the model\n",
        "in_shape = (100000, 1)\n",
        "data = np.random.normal(size=in_shape)\n",
        "\n",
        "model = hk.transform(simple_nn)\n",
        "params = model.init(prng, data)\n",
        "\n",
        "# Run the model a lot, without coming back from the TPU, using jax.laxi.fori_loop\n",
        "# Note that when not doing this (i.e. syncing relatively often between TPU and host) the regular, one device versions\n",
        "# will often be _faster_ than the multi-device version!\n",
        "def predict(x):\n",
        "    x = jax.lax.fori_loop(0, 10000, lambda _, xt: model.apply(params, None, xt), x) # Probably a good idea to do this for your training loop!\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cff2dbae18f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Set up the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0min_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_nn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onMqY8vVvyQz",
        "outputId": "1cbda6a7-4d97-41df-9fe2-c81a77ea8099"
      },
      "source": [
        "# Run using only one device, with jit()\n",
        "basic_jitted = jit(predict)\n",
        "\n",
        "print(\"jit(), first run:\") # Run things twice - first time includes compilation, second does not\n",
        "data = np.random.normal(size=in_shape)\n",
        "%time print(np.mean(basic_jitted(data)))\n",
        "\n",
        "print(\"\\njit(), second run:\")\n",
        "data = np.random.normal(size=in_shape)\n",
        "%time print(np.mean(basic_jitted(data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jit(), first run:\n",
            "0.0\n",
            "CPU times: user 19.4 s, sys: 53.5 s, total: 1min 12s\n",
            "Wall time: 2min 6s\n",
            "\n",
            "jit(), second run:\n",
            "0.0\n",
            "CPU times: user 17 s, sys: 54.3 s, total: 1min 11s\n",
            "Wall time: 2min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf_Z2UQAv2Z7",
        "outputId": "57e63b5a-b1bf-4302-c945-3ec97a09f55e"
      },
      "source": [
        "# Now, do the same using xmap - but still only a single device \n",
        "# All we've done is name the first axis in the input \"batch\"\n",
        "in_axes = [\"batch\", ...]\n",
        "out_axes = [\"batch\", ...]\n",
        "basic_xmapped = xmap(predict, in_axes, out_axes)\n",
        "\n",
        "print(\"\\nxmap(), first run:\")\n",
        "data = np.random.normal(size=in_shape)\n",
        "%time print(np.mean(basic_xmapped(data)))\n",
        "\n",
        "print(\"\\nxmap(), second run:\")\n",
        "data = np.random.normal(size=in_shape)\n",
        "%time print(np.mean(basic_xmapped(data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "xmap(), first run:\n",
            "0.0\n",
            "CPU times: user 18.5 s, sys: 54.9 s, total: 1min 13s\n",
            "Wall time: 2min 6s\n",
            "\n",
            "xmap(), second run:\n",
            "0.0\n",
            "CPU times: user 17 s, sys: 54.3 s, total: 1min 11s\n",
            "Wall time: 2min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SMuwHspv9JE",
        "outputId": "40bbf047-0e1f-49a1-bc53-a531855eb571"
      },
      "source": [
        "# Now, lets use xmap but also have it run our batch in parallel on multiple TPU devices (cores)\n",
        "# Note that for this, the axis length must be evenly divisible by the device count!\n",
        "# Things are now fast!\n",
        "parallel_xmapped = xmap(predict, in_axes, out_axes, axis_resources={'batch': 'batch_tpus'})\n",
        "with mesh(jax.devices(), ('batch_tpus',)):\n",
        "    print(\"\\nxmap(), parallel, first run:\")\n",
        "    data = np.random.normal(size=in_shape)\n",
        "    %time print(np.mean(parallel_xmapped(data)))\n",
        "\n",
        "    print(\"\\nxmap(), parallel, second run:\")\n",
        "    data = np.random.normal(size=in_shape)\n",
        "    %time print(np.mean(parallel_xmapped(data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "xmap(), parallel, first run:\n",
            "0.0\n",
            "CPU times: user 4 s, sys: 8.89 s, total: 12.9 s\n",
            "Wall time: 21.4 s\n",
            "\n",
            "xmap(), parallel, second run:\n",
            "0.0\n",
            "CPU times: user 2.7 s, sys: 8.35 s, total: 11 s\n",
            "Wall time: 19.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI215Of8RCxh"
      },
      "source": [
        "# Next up:\n",
        "\n",
        "Tomorrow, we convert the MNIST network to train in parallel!"
      ]
    }
  ]
}